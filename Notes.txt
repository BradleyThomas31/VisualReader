In Progress
- create basic mobile app simulator
- connect language model, experiment with basic inputs
- connect OCR, experiment with basic inputs

To Do
- connect OCR and LLM together
- add output section, figure out how to make it spoken
- add phoro input from user
- add question input from user
- styling and other
- settings page to change styling 

- text generation for answer or simple answer? 

Completed
researched and installed xcode, swift, BERT, PyTesseract

Notes
  BERT
  -  https://github.com/kyaiooiayk/Awesome-LLM-Large-Language-Models-    Notes/blob/main/tutorials/HuggingFace%20question%20answering%20within%20context.ipynb

  PyTesseract
  -  https://pypi.org/project/pytesseract/
